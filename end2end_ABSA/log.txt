(base) ➜ E2E_ABSA (main) ✗ sh train.sh
01/28/2023 10:59:29 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
01/28/2023 10:59:39 - INFO - filelock - Lock 140211428028032 acquired on ./cache/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock
Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 440M/440M [08:13<00:00, 892kB/s]
01/28/2023 11:07:53 - INFO - filelock - Lock 140211428028032 released on ./cache/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertABSATagger: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertABSATagger from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertABSATagger from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertABSATagger were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'tagger.linear2.weight', 'tagger.linear1.weight', 'bert.embeddings.position_ids', 'tagger.norm1.bias', 'classifier.bias', 'tagger.self_attn.out_proj.bias', 'tagger.self_attn.out_proj.weight', 'tagger.self_attn.in_proj_weight', 'tagger.norm1.weight', 'tagger.norm2.bias', 'tagger.self_attn.in_proj_bias', 'tagger.linear1.bias', 'tagger.norm2.weight', 'tagger.linear2.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
cached_features_file: ./data/laptop14/cached_train_bert-base-uncased_128_laptop14
01/28/2023 11:07:55 - INFO - __main__ - ***** Running training *****
01/28/2023 11:07:55 - INFO - __main__ -   Num examples = 2741
01/28/2023 11:07:55 - INFO - __main__ -   Num Epochs = 9
01/28/2023 11:07:55 - INFO - __main__ -   Instantaneous batch size per GPU = 16
01/28/2023 11:07:55 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
01/28/2023 11:07:55 - INFO - __main__ -   Gradient Accumulation steps = 1
01/28/2023 11:07:55 - INFO - __main__ -   Total optimization steps = 1500
Epoch:   0%|                                                                                                                                                                  | 0/9 [00:00<?, ?it/s]
01/28/2023 11:24:33 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-100                                                       | 99/172 [16:27<11:43,  9.63s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [29:06<00:00, 10.16s/it]
Epoch:  11%|████████████████▋                                                                                                                                     | 1/9 [29:06<3:52:55, 1746.91s/it]
01/28/2023 11:41:54 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-200                                                       | 27/172 [04:40<25:07, 10.40s/it]

01/28/2023 11:58:38 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-300███████████████▊                                      | 127/172 [21:25<07:11,  9.59s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [28:32<00:00,  9.96s/it]
Epoch:  22%|█████████████████████████████████▎                                                                                                                    | 2/9 [57:39<3:21:27, 1726.80s/it]
01/28/2023 12:14:35 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-400                                                       | 55/172 [08:49<18:41,  9.58s/it]

01/28/2023 12:30:50 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-500███████████████████████████████████████▌              | 155/172 [25:03<03:04, 10.86s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [27:52<00:00,  9.72s/it]
Epoch:  33%|█████████████████████████████████████████████████▎                                                                                                  | 3/9 [1:25:31<2:50:10, 1701.80s/it]
01/28/2023 12:48:54 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-600                                                       | 83/172 [15:15<16:30, 11.13s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [29:35<00:00, 10.33s/it]
Epoch:  44%|█████████████████████████████████████████████████████████████████▊                                                                                  | 4/9 [1:55:07<2:24:15, 1731.09s/it]
01/28/2023 13:04:59 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-700                                                       | 11/172 [01:45<25:41,  9.57s/it]

01/28/2023 13:21:14 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-800██▏                                                   | 111/172 [18:00<10:05,  9.92s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [27:56<00:00,  9.75s/it]
Epoch:  56%|██████████████████████████████████████████████████████████████████████████████████▏                                                                 | 5/9 [2:23:04<1:54:06, 1711.50s/it]
01/28/2023 13:37:37 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-900                                                       | 39/172 [06:26<21:39,  9.77s/it]

01/28/2023 13:54:03 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-1000████████████████████████▉                            | 139/172 [22:53<05:29,  9.98s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [28:17<00:00,  9.87s/it]
Epoch:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                 | 6/9 [2:51:22<1:25:20, 1706.82s/it]
01/28/2023 14:12:18 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-1100                                                      | 67/172 [12:48<20:19, 11.62s/it]

01/28/2023 14:31:29 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-1200████████████████████████████████████████████████▊    | 167/172 [32:00<00:50, 10.16s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [32:45<00:00, 11.43s/it]
Epoch:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 7/9 [3:24:07<59:42, 1791.39s/it]
01/28/2023 14:48:20 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-1300                                                      | 95/172 [16:06<12:59, 10.13s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 172/172 [28:56<00:00, 10.10s/it]
Epoch:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 8/9 [3:53:04<29:33, 1774.00s/it]
01/28/2023 15:05:01 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-1400                                                      | 23/172 [03:51<24:14,  9.76s/it]

01/28/2023 15:21:47 - INFO - __main__ - Saving model checkpoint to bert-tfm-laptop14-finetune/checkpoint-1500███████████▍                                         | 123/172 [20:37<08:13, 10.07s/it]
Iteration:  72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 124/172 [20:57<08:06, 10.14s/it]
Epoch:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 8/9 [4:14:02<31:45, 1905.28s/it]
01/28/2023 15:22:00 - INFO - __main__ - Perform validation on the following checkpoints: ['bert-tfm-laptop14-finetune/checkpoint-100', 'bert-tfm-laptop14-finetune/checkpoint-1000', 'bert-tfm-laptop14-finetune/checkpoint-1100', 'bert-tfm-laptop14-finetune/checkpoint-1200', 'bert-tfm-laptop14-finetune/checkpoint-1300', 'bert-tfm-laptop14-finetune/checkpoint-1400', 'bert-tfm-laptop14-finetune/checkpoint-1500', 'bert-tfm-laptop14-finetune/checkpoint-200', 'bert-tfm-laptop14-finetune/checkpoint-300', 'bert-tfm-laptop14-finetune/checkpoint-400', 'bert-tfm-laptop14-finetune/checkpoint-500', 'bert-tfm-laptop14-finetune/checkpoint-600', 'bert-tfm-laptop14-finetune/checkpoint-700', 'bert-tfm-laptop14-finetune/checkpoint-800', 'bert-tfm-laptop14-finetune/checkpoint-900', 'bert-tfm-laptop14-finetune']
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:58<00:00,  1.54s/it]
class_count: [104. 106.  46.]
01/28/2023 15:23:01 - INFO - __main__ -   eval_loss = 0.20263582311178507
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:25<00:00,  1.46s/it]
class_count: [339. 130. 165.]
01/28/2023 15:25:28 - INFO - __main__ -   eval_loss = 0.25079431164078414
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [01:00<00:00,  1.59s/it]
class_count: [104. 106.  46.]
01/28/2023 15:26:30 - INFO - __main__ -   eval_loss = 0.15422334786087863
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:28<00:00,  1.48s/it]
class_count: [339. 130. 165.]
01/28/2023 15:28:58 - INFO - __main__ -   eval_loss = 0.1777984906185884
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:58<00:00,  1.55s/it]
class_count: [104. 106.  46.]
01/28/2023 15:29:59 - INFO - __main__ -   eval_loss = 0.1568291445850934
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:26<00:00,  1.46s/it]
class_count: [339. 130. 165.]
01/28/2023 15:32:25 - INFO - __main__ -   eval_loss = 0.18922731508384458
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:59<00:00,  1.57s/it]
class_count: [104. 106.  46.]
01/28/2023 15:33:27 - INFO - __main__ -   eval_loss = 0.15657316925200193
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:27<00:00,  1.47s/it]
class_count: [339. 130. 165.]
01/28/2023 15:35:55 - INFO - __main__ -   eval_loss = 0.18860961932805367
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [01:00<00:00,  1.58s/it]
class_count: [104. 106.  46.]
01/28/2023 15:36:57 - INFO - __main__ -   eval_loss = 0.1621496273253701
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:33<00:00,  1.54s/it]
class_count: [339. 130. 165.]
01/28/2023 15:39:31 - INFO - __main__ -   eval_loss = 0.18653204419533723
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [01:01<00:00,  1.62s/it]
class_count: [104. 106.  46.]
01/28/2023 15:40:35 - INFO - __main__ -   eval_loss = 0.16039832175929883
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:27<00:00,  1.47s/it]
class_count: [339. 130. 165.]
01/28/2023 15:43:02 - INFO - __main__ -   eval_loss = 0.18605743149935733
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [01:03<00:00,  1.68s/it]
class_count: [104. 106.  46.]
01/28/2023 15:44:08 - INFO - __main__ -   eval_loss = 0.16081743434953846
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:27<00:00,  1.47s/it]
class_count: [339. 130. 165.]
01/28/2023 15:46:36 - INFO - __main__ -   eval_loss = 0.18809894477832131
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:59<00:00,  1.57s/it]
class_count: [104. 106.  46.]
01/28/2023 15:47:38 - INFO - __main__ -   eval_loss = 0.15643221159514628
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:35<00:00,  1.56s/it]
class_count: [339. 130. 165.]
01/28/2023 15:50:14 - INFO - __main__ -   eval_loss = 0.20937007434666158
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [01:10<00:00,  1.86s/it]
class_count: [104. 106.  46.]
01/28/2023 15:51:27 - INFO - __main__ -   eval_loss = 0.13500533179429017
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:33<00:00,  1.53s/it]
class_count: [339. 130. 165.]
01/28/2023 15:54:00 - INFO - __main__ -   eval_loss = 0.17240668781567364
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [01:03<00:00,  1.66s/it]
class_count: [104. 106.  46.]
01/28/2023 15:55:06 - INFO - __main__ -   eval_loss = 0.14469350933244354
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:33<00:00,  1.53s/it]
class_count: [339. 130. 165.]
01/28/2023 15:57:39 - INFO - __main__ -   eval_loss = 0.1559490769216791
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [01:01<00:00,  1.61s/it]
class_count: [104. 106.  46.]
01/28/2023 15:58:42 - INFO - __main__ -   eval_loss = 0.1406800759171969
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:31<00:00,  1.52s/it]
class_count: [339. 130. 165.]
01/28/2023 16:01:14 - INFO - __main__ -   eval_loss = 0.1559526039706543
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:58<00:00,  1.55s/it]
class_count: [104. 106.  46.]
01/28/2023 16:02:15 - INFO - __main__ -   eval_loss = 0.14285127745058976
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:23<00:00,  1.44s/it]
class_count: [339. 130. 165.]
01/28/2023 16:04:39 - INFO - __main__ -   eval_loss = 0.16650966492248698
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:57<00:00,  1.52s/it]
class_count: [104. 106.  46.]
01/28/2023 16:05:38 - INFO - __main__ -   eval_loss = 0.14142181908123588
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:23<00:00,  1.44s/it]
class_count: [339. 130. 165.]
01/28/2023 16:08:02 - INFO - __main__ -   eval_loss = 0.16692974095232785
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:57<00:00,  1.52s/it]
class_count: [104. 106.  46.]
01/28/2023 16:09:02 - INFO - __main__ -   eval_loss = 0.14707258247500776
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:22<00:00,  1.43s/it]
class_count: [339. 130. 165.]
01/28/2023 16:11:24 - INFO - __main__ -   eval_loss = 0.17923527559032665
cached_features_file: ./data/laptop14/cached_dev_bert-base-uncased_128_laptop14
Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:58<00:00,  1.54s/it]
class_count: [104. 106.  46.]
01/28/2023 16:12:25 - INFO - __main__ -   eval_loss = 0.15160235321443333
cached_features_file: ./data/laptop14/cached_test_bert-base-uncased_128_laptop14
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:26<00:00,  1.46s/it]
class_count: [339. 130. 165.]
01/28/2023 16:14:51 - INFO - __main__ -   eval_loss = 0.18054172046249733
01/28/2023 16:14:51 - INFO - __main__ -
The best checkpoint is bert-tfm-laptop14-finetune/checkpoint-1100
test-micro-f1_1100: 0.60532, test-eval_loss_1100: 0.18923, dev-micro-f1_1100: 0.61623, dev-eval_loss_1100: 0.15683
test-micro-f1_1200: 0.60736, test-eval_loss_1200: 0.18861, dev-micro-f1_1200: 0.60589, dev-eval_loss_1200: 0.15657
test-micro-f1_1300: 0.61633, test-eval_loss_1300: 0.18653, dev-micro-f1_1300: 0.60424, dev-eval_loss_1300: 0.16215
test-micro-f1_1400: 0.61609, test-eval_loss_1400: 0.18606, dev-micro-f1_1400: 0.60814, dev-eval_loss_1400: 0.16040
test-micro-f1_1500: 0.61396, test-eval_loss_1500: 0.18810, dev-micro-f1_1500: 0.58864, dev-eval_loss_1500: 0.16082
(base) ➜ E2E_ABSA (main) ✗
